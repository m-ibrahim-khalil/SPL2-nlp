{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiDAF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsse1009/SPL2-nlp/blob/master/BiDAF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3clK7_CJ8CM"
      },
      "source": [
        "from keras.layers import Layer\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers.advanced_activations import Softmax\r\n",
        "\r\n",
        "class SimilarityMatrix(Layer):\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super(SimilarityMatrix, self).__init__(**kwargs)\r\n",
        "  \r\n",
        "  def build(self, input_shape):\r\n",
        "    self.context_shape = input_shape[0]\r\n",
        "    self.question_shape = input_shape[1]\r\n",
        "\r\n",
        "    self.kernel = self.add_weight(name=\"kernel\",\r\n",
        "                                  shape=(3 * input_shape[0][2], 1),\r\n",
        "                                  initializer='uniform',\r\n",
        "                                  trainable=True)\r\n",
        "\r\n",
        "    super(SimilarityMatrix, self).build(input_shape)\r\n",
        "\r\n",
        "  def compute_similarity(self, repeated_context_vectors, repeated_query_vectors):\r\n",
        "\r\n",
        "    element_wise_multiply = repeated_context_vectors * repeated_query_vectors\r\n",
        "    concatenated_tensor = tf.concat(\r\n",
        "    [repeated_context_vectors, repeated_query_vectors, element_wise_multiply], axis=-1)\r\n",
        "    dot_product = K.squeeze(K.dot(concatenated_tensor, self.kernel), axis=-1)\r\n",
        "\r\n",
        "    return dot_product\r\n",
        "\r\n",
        "  def build_similarity_matrix(self, context, question):\r\n",
        "\r\n",
        "    num_context_words = K.shape(context)[1]\r\n",
        "    num_query_words = K.shape(question)[1]\r\n",
        "\r\n",
        "    context_dim_repeat = K.concatenate([[1, 1], [num_query_words], [1]], 0)\r\n",
        "    query_dim_repeat = K.concatenate([[1], [num_context_words], [1, 1]], 0)\r\n",
        "    repeated_context_vectors = K.tile(K.expand_dims(context, axis=2), context_dim_repeat)\r\n",
        "    repeated_query_vectors = K.tile(K.expand_dims(question, axis=1), query_dim_repeat)\r\n",
        "    similarity_matrix = self.compute_similarity(repeated_context_vectors, repeated_query_vectors)\r\n",
        "    # similarity_matrix = tf.reshape(similarity_matrix, [self.context_shape[0],self.context_shape[1],self.question_shape[1]])\r\n",
        "\r\n",
        "    return similarity_matrix\r\n",
        "\r\n",
        "  def call(self, x):\r\n",
        "    context, question = x\r\n",
        "    self.similarity_matrix = self.build_similarity_matrix(context, question)\r\n",
        "    return self.similarity_matrix\r\n",
        "  \r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "    return (input_shape[0][0],input_shape[0][1],input_shape[1][1])\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUWc2KL1QUwR"
      },
      "source": [
        "from keras.layers import Layer\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers.advanced_activations import Softmax\r\n",
        "\r\n",
        "class C2Q_Layer(Layer):\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super(C2Q_Layer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    super(C2Q_Layer, self).build(input_shape)\r\n",
        "\r\n",
        "  def call(self,x):\r\n",
        "    similarity_matrix, question=x\r\n",
        "    attention = tf.nn.softmax(similarity_matrix)\r\n",
        "\r\n",
        "    self.U_A=K.sum(K.dot(attention,question),-2)\r\n",
        "\r\n",
        "    return self.U_A\r\n",
        "\r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "    return self.U_A.shape;"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSY1V1QQgqU-"
      },
      "source": [
        "from keras.layers import Layer\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers.advanced_activations import Softmax\r\n",
        "\r\n",
        "class Q2C_Layer(Layer):\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super(Q2C_Layer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    super(Q2C_Layer, self).build(input_shape)\r\n",
        "\r\n",
        "  def call(self,x):\r\n",
        "    similarity_matrix, context=x\r\n",
        "    attention = tf.nn.softmax(K.max(similarity_matrix,axis=-1))\r\n",
        "\r\n",
        "    temp=K.expand_dims(K.sum(K.dot(attention,context),-2),1)\r\n",
        "\r\n",
        "    H_A=K.tile(temp,[1,similarity_matrix.shape[1],1])\r\n",
        "\r\n",
        "    return H_A\r\n",
        "  \r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "    return self.H_A.shape;"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc17-PoNk9i_"
      },
      "source": [
        "from keras.layers import Layer\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers.advanced_activations import Softmax\r\n",
        "\r\n",
        "class MegaMerge(Layer):\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    super(MegaMerge, self).__init__(**kwargs)\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    super(MegaMerge, self).build(input_shape)\r\n",
        "\r\n",
        "  def call(self,x):\r\n",
        "    context,c2q,q2c=x\r\n",
        "    self.G=K.concatenate([context,c2q,context*c2q,context*q2c],axis=-1)\r\n",
        "\r\n",
        "    return self.G;\r\n",
        "\r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "    return self.G.shape;"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpW87WpJnGoR"
      },
      "source": [
        "from keras.layers import Layer,LSTM,Bidirectional\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "class ModellingLayer(Layer):\r\n",
        "    def __init__(self,**kwargs):\r\n",
        "        super(ModellingLayer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.shape=input_shape\r\n",
        "  \r\n",
        "        self.lstm1 = Bidirectional(LSTM(int(input_shape[2]//8),\r\n",
        "                                   activation='sigmoid',\r\n",
        "                                   input_shape=(input_shape[1],input_shape[2]),\r\n",
        "                                   return_sequences=True, trainable=True))\r\n",
        "        self.lstm2 = Bidirectional(LSTM(int(input_shape[2]//8),\r\n",
        "                                   activation='sigmoid',\r\n",
        "                                   input_shape=(input_shape[1], int(input_shape[2]//4)),\r\n",
        "                                   return_sequences=True, trainable=True))\r\n",
        "        super(ModellingLayer, self).build(input_shape)\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "        \r\n",
        "        self.M1=self.lstm1(x)\r\n",
        "        \r\n",
        "        self.M2=self.lstm2(self.M1)\r\n",
        "        \r\n",
        "        self.temp1=tf.concat([x, self.M1], -1)\r\n",
        "        self.temp2=tf.concat([x, self.M2], -1)\r\n",
        "        \r\n",
        "        return self.temp1,self.temp2\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        return self.temp1.shape,self.temp2.shape"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqbVUKxcrp4I"
      },
      "source": [
        "from keras.layers import Layer\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "class OutputLayer(Layer):\r\n",
        "    def __init__(self,**kwargs):\r\n",
        "        super(OutputLayer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "    def build(self,input_shape):\r\n",
        "  \r\n",
        "        self.w1=self.add_weight(name=\"w1\",\r\n",
        "                                shape=(input_shape[0][2],),\r\n",
        "                                initializer='uniform',\r\n",
        "                                trainable=True)\r\n",
        "        self.w2=self.add_weight(name=\"w2\",\r\n",
        "                                shape=(input_shape[0][2],),\r\n",
        "                                initializer='uniform',\r\n",
        "                                trainable=True)\r\n",
        "\r\n",
        "        super(OutputLayer, self).build(input_shape)\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "\r\n",
        "        answer_span1=tf.tensordot(x[0],tf.transpose(self.w1),1)\r\n",
        "        answer_span2=tf.tensordot(x[1], tf.transpose(self.w2), 1)\r\n",
        "        \r\n",
        "        self.p1=tf.nn.softmax(answer_span1)\r\n",
        "        self.p2=tf.nn.softmax(answer_span2)\r\n",
        "        \r\n",
        "        \r\n",
        "        return self.p1,self.p2\r\n",
        "\r\n",
        "    def compute_output_shape(self, input_shape):\r\n",
        "        return self.p1.shape,self.p2.shape\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v499xPDC-OZQ",
        "outputId": "3ac056ef-71a6-400f-ba22-5665cf7484b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.models import Model, load_model\r\n",
        "\r\n",
        "passage_input = Input(shape=(766, 800), dtype='float32', name=\"passage_input\")\r\n",
        "question_input = Input(shape=(60, 800), dtype='float32', name=\"question_input\")\r\n",
        "sim=SimilarityMatrix(name=\"sm\")([passage_input, question_input])\r\n",
        "c2q=C2Q_Layer(name=\"c2q\")([sim, question_input])\r\n",
        "q2c=Q2C_Layer(name=\"q2c\")([sim, passage_input])\r\n",
        "megamerge=MegaMerge(name=\"mega\")([passage_input, c2q, q2c])\r\n",
        "t1, t2=ModellingLayer(name=\"modelling\")(megamerge)\r\n",
        "p1, p2=OutputLayer(name=\"output\")([t1, t2])\r\n",
        "\r\n",
        "model = Model(inputs=[passage_input, question_input], outputs=[p1, p2])\r\n",
        "model.summary()\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "passage_input (InputLayer)      [(None, 766, 800)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question_input (InputLayer)     [(None, 60, 800)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sm (SimilarityMatrix)           (None, 766, 60)      2400        passage_input[0][0]              \n",
            "                                                                 question_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "c2q (C2Q_Layer)                 (None, 766, 800)     0           sm[0][0]                         \n",
            "                                                                 question_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "q2c (Q2C_Layer)                 (None, 766, 800)     0           sm[0][0]                         \n",
            "                                                                 passage_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mega (MegaMerge)                (None, 766, 3200)    0           passage_input[0][0]              \n",
            "                                                                 c2q[0][0]                        \n",
            "                                                                 q2c[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "modelling (ModellingLayer)      ((None, 766, 4000),  15366400    mega[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "output (OutputLayer)            ((None, 766), (None, 8000        modelling[0][0]                  \n",
            "                                                                 modelling[0][1]                  \n",
            "==================================================================================================\n",
            "Total params: 15,376,800\n",
            "Trainable params: 15,376,800\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8BtfKie_8kt",
        "outputId": "7025ae73-d49b-4802-94aa-ad0beacd67c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "context=np.random.rand(10,766,800)\r\n",
        "question=np.random.rand(10,60,800)\r\n",
        "p1 = np.zeros((10, 766))\r\n",
        "p2 = np.ones((10, 766))\r\n",
        "model.fit(x={\"passage_input\": context, \"question_input\": question}, y={\"output\": p1, \"output_1\": p2}, batch_size = 5, steps_per_epoch=1,\r\n",
        "                                  epochs=10, verbose = 2)\r\n",
        "model.save('bidaf1009.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 - 3s - loss: 5476.0186 - output_loss: 0.0000e+00 - output_1_loss: 5476.0186 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 - 2s - loss: 982248.3750 - output_loss: 0.0000e+00 - output_1_loss: 982248.3750 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 - 2s - loss: 2251941.5000 - output_loss: 0.0000e+00 - output_1_loss: 2251941.5000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 - 2s - loss: 3456517.2500 - output_loss: 0.0000e+00 - output_1_loss: 3456517.2500 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 - 2s - loss: 4551021.5000 - output_loss: 0.0000e+00 - output_1_loss: 4551021.5000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 - 2s - loss: 5395752.0000 - output_loss: 0.0000e+00 - output_1_loss: 5395752.0000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 - 2s - loss: 7550355.0000 - output_loss: 0.0000e+00 - output_1_loss: 7550355.0000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 - 2s - loss: 7767915.0000 - output_loss: 0.0000e+00 - output_1_loss: 7767915.0000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 - 2s - loss: 8277968.0000 - output_loss: 0.0000e+00 - output_1_loss: 8277968.0000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 - 2s - loss: 10337394.0000 - output_loss: 0.0000e+00 - output_1_loss: 10337394.0000 - output_accuracy: 0.0000e+00 - output_1_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8tjuEY52ecK",
        "outputId": "3a6d25e2-b36f-4d0c-fcd8-cbac74327a2b"
      },
      "source": [
        "\r\n",
        "context=np.random.rand(10,766,800)\r\n",
        "question=np.random.rand(10,60,800)\r\n",
        "\r\n",
        "sim=SimilarityMatrix()\r\n",
        "c2q=C2Q_Layer()\r\n",
        "q2c=Q2C_Layer()\r\n",
        "megamerge=MegaMerge()\r\n",
        "modelling=ModellingLayer()\r\n",
        "output=OutputLayer()\r\n",
        "x=sim([context,question])\r\n",
        "y=c2q([x,question])\r\n",
        "z=q2c([x,context])\r\n",
        "g=megamerge([context,y,z])\r\n",
        "temp1,temp2=modelling(g)\r\n",
        "p1,p2=output([temp1,temp2])\r\n",
        "print(p1,p2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1.04814804e-04 2.34403997e-03 1.44748537e-05 ... 1.56190433e-03\n",
            "  1.35314977e-03 6.91540889e-04]\n",
            " [1.55857124e-05 5.33449638e-05 3.14282114e-03 ... 1.90216408e-03\n",
            "  3.33979202e-04 3.36068263e-03]\n",
            " [1.71619225e-02 8.08488330e-05 2.37535243e-03 ... 5.25931595e-04\n",
            "  1.75154855e-04 3.91609465e-05]\n",
            " ...\n",
            " [1.22528465e-04 4.26990911e-03 6.04337765e-06 ... 6.11135969e-04\n",
            "  1.68583210e-04 4.87228681e-04]\n",
            " [6.90609356e-03 8.33049053e-05 1.95606353e-05 ... 1.85843033e-04\n",
            "  1.43067999e-04 2.20585891e-04]\n",
            " [4.04190941e-04 1.92559499e-03 7.71209307e-05 ... 4.30966169e-03\n",
            "  9.72436450e-04 6.74650346e-06]], shape=(10, 766), dtype=float32) tf.Tensor(\n",
            "[[2.2800332e-03 1.4471752e-03 5.7612539e-05 ... 2.0602587e-05\n",
            "  2.2411338e-04 5.3683692e-04]\n",
            " [2.3282437e-05 4.6944010e-04 1.9887715e-04 ... 3.0302914e-04\n",
            "  6.0676412e-05 4.5623918e-04]\n",
            " [7.3930188e-03 9.0660404e-05 1.2603401e-04 ... 5.0517321e-03\n",
            "  3.3784917e-04 2.2127411e-04]\n",
            " ...\n",
            " [6.2175986e-04 1.0171512e-03 3.5310307e-04 ... 6.0830370e-04\n",
            "  2.3957987e-04 2.4804038e-03]\n",
            " [2.8463131e-05 5.0379476e-05 1.5715312e-03 ... 3.9176748e-04\n",
            "  2.4778207e-04 3.4960851e-04]\n",
            " [8.6677283e-06 2.3186023e-05 2.2530414e-03 ... 4.7144187e-03\n",
            "  1.2267716e-03 1.6432026e-04]], shape=(10, 766), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}